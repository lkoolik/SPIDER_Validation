{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aerodynamic Particle Sizer (APS) Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Christopher Rapp\n",
    "\n",
    "rapp5@purdue.edu\n",
    "\n",
    "**Notes:** If you are confused or stuck on certain portions of the code, print out the variables you are producing while proceeding through the code to better understand the process\n",
    "\n",
    "This code assumes _Set# has manually been appended to the end of the exported csv files from AIM\n",
    "It additionally assumes that dW, column wise, and comma seperated are the export parameters\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SECTION:** Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from numpy import linspace\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from scipy.optimize import curve_fit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SECTION:** Define working directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of files necessary\n",
    "import_APS = '/Users/christopherrapp/Documents/Purdue/Data_SPIDER/calibrations/import/l_pcvi/APS/'\n",
    "\n",
    "# Location to send results\n",
    "export_results = '/Users/christopherrapp/Documents/Purdue/Data_SPIDER/calibrations/export/l_pcvi/'\n",
    "\n",
    "# Location to send plots\n",
    "export_plots = '/Users/christopherrapp/Documents/Purdue/Data_SPIDER/calibrations/plots/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SECTION:** List directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['20210810_1348_PF45_AF6_7_SF6_5_AIF5_glassbeads_Set3.TXT',\n",
       "  '20210810_1456_PF45_AF7_0_SF6_5_AIF5_glassbeads_Set6.TXT',\n",
       "  '20210810_1250_PF45_AF6_5_SF6_5_AIF5_glassbeads_Set1.TXT',\n",
       "  '20210810_1522_PF0_AF0_SF6_5_AIF5_glassbeads_Set7.TXT',\n",
       "  '20210810_1535_PF0_AF0_SF6_5_AIF5_glassbeads_Set8.TXT',\n",
       "  '20210810_1326_PF0_AF0_SF6_5_AIF5_glassbeads_Set1.TXT',\n",
       "  '20210810_1335_PF45_AF6_6_SF6_5_AIF5_glassbeads_Set2.TXT',\n",
       "  '20210810_1516_PF45_AF7_1_SF6_5_AIF5_glassbeads_Set7.TXT',\n",
       "  '20210810_1529_PF45_AF7_2_SF6_5_AIF5_glassbeads_Set8.TXT',\n",
       "  '20210810_1550_PF0_AF0_SF6_5_AIF5_glassbeads_Set9.TXT',\n",
       "  '20210810_1423_PF0_AF0_SF6_5_AIF5_glassbeads_Set4.TXT',\n",
       "  '20210810_1611_PF45_AF7_5_SF6_5_AIF5_glassbeads_Set11.TXT',\n",
       "  '20210810_1544_PF45_AF7_3_SF6_5_AIF5_glassbeads_Set9.TXT',\n",
       "  '20210810_1449_PF0_AF0_SF6_5_AIF5_glassbeads_Set5.TXT',\n",
       "  '20210810_1617_PF0_AF0_SF6_5_AIF5_glassbeads_Set11.TXT',\n",
       "  '20210810_1430_PF45_AF6_9_SF6_5_AIF5_glassbeads_Set5.TXT',\n",
       "  '20210810_1402_PF0_AF0_SF6_5_AIF5_glassbeads_Set3.TXT',\n",
       "  '20210810_1341_PF0_AF0_SF6_5_AIF5_glassbeads_Set2.TXT',\n",
       "  '20210810_1503_PF0_AF0_SF6_5_AIF5_glassbeads_Set6.TXT',\n",
       "  '20210810_1558_PF45_AF7_4_SF6_5_AIF5_glassbeads_Set10.TXT',\n",
       "  '20210810_1604_PF0_AF0_SF6_5_AIF5_glassbeads_Set10.TXT',\n",
       "  '20210810_1417_PF45_AF6_8_SF6_5_AIF5_glassbeads_Set4.TXT'],\n",
       " ['20210909_1304_PF0_AF0_SF6.5_AIF5_glassbeads_Set2.txt',\n",
       "  '20210909_1312_PF45_AF6.8_SF6.5_AIF5_glassbeads_Set4.txt',\n",
       "  '20210909_1327_PF0_AF0_SF6.5_AIF5_glassbeads_Set6.txt',\n",
       "  '20210909_1317_PF0_AF0_SF6.5_AIF5_glassbeads_Set4.txt',\n",
       "  '20210909_1322_PF0_AF0_SF6.5_AIF5_glassbeads_Set5.txt',\n",
       "  '20210909_1320_PF45_AF6.7_SF6.5_AIF5_glassbeads_Set5.txt',\n",
       "  '20210909_1133_zerocheck.txt',\n",
       "  '20210909_1310_PF0_AF0_SF6.5_AIF5_glassbeads_Set3.txt',\n",
       "  '20210909_1324_PF45_AF6.6_SF6.5_AIF5_glassbeads_Set6.txt',\n",
       "  '20210909_1210_background.txt',\n",
       "  '20210909_1307_PF45_AF6.9_SF6.5_AIF5_glassbeads_Set3.txt',\n",
       "  '20210909_1301_PF45_AF7.1_SF6.5_AIF5_glassbeads_Set2.txt',\n",
       "  '20210909_1258_PF0_AF0_SF6.5_AIF5_glassbeads_Set1.txt',\n",
       "  '20210909_1252_PF45_AF7.3_SF6.5_AIF5_glassbeads_Set1.txt'],\n",
       " ['20210901_1646_PF0_AF0_SF2.5_AIF5_glassbeads_Set2.txt',\n",
       "  '20210901_1709_PF45_AF6.7_SF5.5_AIF5_glassbeads_Set5.txt',\n",
       "  '20210901_1719_PF0_AF0_SF6.5_AIF5_glassbeads_Set6.txt',\n",
       "  '20210901_1641_PF45_AF6.7_SF2.5_AIF5_glassbeads_Set2.txt',\n",
       "  '20210901_1700_PF45_AF6.7_SF4.5_AIF5_glassbeads_Set4.txt',\n",
       "  '20210901_1715_PF45_AF6.7_SF6.5_AIF5_glassbeads_Set6.txt',\n",
       "  '20210901_1650_PF45_AF6.7_SF3.5_AIF5_glassbeads_Set3.txt',\n",
       "  '20210901_1653_PF0_AF0_SF3.5_AIF5_glassbeads_Set3.txt',\n",
       "  '20210901_1629_PF0_AF0_SF1.5_AIF5_glassbeads_Set1.txt',\n",
       "  '20210901_1703_PF0_AF0_SF3.5_AIF5_glassbeads_Set4.txt',\n",
       "  '20210901_1622_PF45_AF6.7_SF1.5_AIF5_glassbeads_Set1.txt',\n",
       "  '20210901_1613_background.txt',\n",
       "  '20210901_1713_PF0_AF0_SF5.5_AIF5_glassbeads_Set5.txt'],\n",
       " ['20210731_1738_PF0_AF0_SF6_5_AIF5_glassbeads_Set2.txt',\n",
       "  '20210731_1834_PF0_AF0_SF6_5_AIF5_glassbeads_Set6.txt',\n",
       "  '20210731_1804_PF78_AF8_5_SF6_5_AIF5_ glassbeads_Set4.txt',\n",
       "  '20210731_1821_PF0_AF0_SF6_5_AIF5_glassbeads_Set5.txt',\n",
       "  '20210731_1857_PF78_AF8_9_SF6_5_AIF5_ glassbeads_Set8.txt',\n",
       "  '20210731_1722_PF0_AF0_SF6_5_AIF5_glassbeads_Set1.txt',\n",
       "  '20210731_1851_PF0_AF0_SF6_5_AIF5_glassbeads_Set7.txt',\n",
       "  '20210731_1828_PF78_AF8_7_SF6_5_AIF5_ glassbeads_Set6.txt',\n",
       "  '20210731_1905_PF0_AF0_SF6_5_AIF5_glassbeads_Set8.txt',\n",
       "  '20210731_1750_PF78_AF8_4_SF6_5_AIF5_ NEWglassbeads_Set3.txt',\n",
       "  '20210731_1816_PF78_AF8_6_SF6_5_AIF5_ glassbeads_Set5.txt',\n",
       "  '20210731_1730_PF78_AF8_2_SF6_5_AIF5_glassbeads_Set2.txt',\n",
       "  '20210731_1810_PF0_AF0_SF6_5_AIF5_glassbeads_Set4.txt',\n",
       "  '20210731_1845_PF78_AF8_8_SF6_5_AIF5_ glassbeads_Set7.txt',\n",
       "  '20210731_1756_PF0_AF0_SF6_5_AIF5_ NEWglassbeads_Set3.txt',\n",
       "  '20210731_1702_PF78_AF8_SF6_5_AIF5_glassbeads_Set1.txt'],\n",
       " ['20210714_1102_test.txt',\n",
       "  '20210714_1503_PF0_AF0_SF6_5_Set2.txt',\n",
       "  '20210714_1503_PF0_AF0_SF6_5_Set1.txt',\n",
       "  '20210714_1440_test.txt',\n",
       "  '20210714_1451_PF35_AF5_SF6_5_Set1.txt',\n",
       "  '20210714_1515_PF40_AF5_6_SF6_5_Set2.txt'],\n",
       " ['20210722_1323_PF0_AF0_SF6_5_AIF5_glassbeads_Set5.txt',\n",
       "  '20210722_1048_PF0_AF0_SF6_5_size_distribution_5lpm_filtered.txt',\n",
       "  '20210722_1441_PF0_AF0_SF2_AIF5_glassbeads_Set6.txt',\n",
       "  '20210722_1457_PF0_AF0_SF2_AIF5_glassbeads_Set7.txt',\n",
       "  '20210722_1056_PF0_AF0_SF6_5_size_distribution_1lpm.txt',\n",
       "  '20210722_1222_PF43_AF10_SF6_7_AIF5_glassbeads_Set3.txt',\n",
       "  '20210722_1455_PF0_AF9_SF2_AIF5_glassbeads_Set7.txt',\n",
       "  '20210722_1251_PF0_AF7_SF6_5_AIF5_glassbeads_Set4.txt',\n",
       "  '20210722_1113_PF30_AF4_48_SF6_5_AIF5_glassbeads_Set1.txt',\n",
       "  '20210722_1156_PF40_AF5_71_SF6_5_AIF5_glassbeads_Set2.txt',\n",
       "  '20210722_1142_PF0_AF0_SF6_5_AIF5_glassbeads_Set1.txt',\n",
       "  '20210722_1510_PF0_AF11_SF2_AIF5_glassbeads_Set8.txt',\n",
       "  '20210722_1245_PF51_AF7_SF6_5_AIF5_glassbeads_Set4.txt',\n",
       "  '20210722_1207_PF0_AF5_71_SF6_5_AIF5_glassbeads_Set2.txt',\n",
       "  '20210722_1505_PF79_AF11_SF2_AIF5_glassbeads_Set8.txt',\n",
       "  '20210722_1234_PF0_AF0_SF6_7_AIF5_glassbeads_Set3.txt',\n",
       "  '20210722_1038_PF0_AF0_SF6_5_size_distribution_5lpm.txt',\n",
       "  '20210722_1311_PF78_AF12_SF6_5_AIF5_glassbeads_Set5.txt',\n",
       "  '20210722_1213_PF0_AF0_SF6_5_AIF5_glassbeads_Set2.txt',\n",
       "  '20210722_1259_PF0_AF0_SF6_5_AIF5_glassbeads_Set4.txt',\n",
       "  '20210722_1512_PF0_AF0_SF2_AIF5_glassbeads_Set8.txt',\n",
       "  '20210722_1438_PF0_AF8_SF2_AIF5_glassbeads_Set6.txt',\n",
       "  '20210722_1317_PF0_AF12_SF6_5_AIF5_glassbeads_Set5.txt',\n",
       "  '20210722_1228_PF0_AF10_SF6_7_AIF5_glassbeads_Set3.txt',\n",
       "  '20210722_1432_PF76_AF8_SF2_AIF5_glassbeads_Set6.txt',\n",
       "  '20210722_1449_PF77_AF9_SF2_AIF5_glassbeads_Set7.txt',\n",
       "  '20210722_1135_PF0_AF4_48_SF6_5_AIF5_glassbeads_Set1.txt',\n",
       "  '20210722_1017_PF0_AF0_SF6_5_ambient_filter.txt'],\n",
       " ['20210715_1219_PF40_AF5_71_SF6_5_Set2.txt',\n",
       "  '20210715_1245_PF30_AF4_48_SF6_5_Set1.txt',\n",
       "  '20210715_1219_PF0_AF0_SF6_5_Set1.txt',\n",
       "  '20210715_1219_PF0_AF0_SF6_5_Set2.txt'],\n",
       " ['20210803_1213_PF0_AF0_SF6_5_AIF5_glassbeads_Set5.txt',\n",
       "  '20210803_1207_PF77_AF8_5_SF6_5_AIF5_glassbeads_Set4.txt',\n",
       "  '20210803_1055_PF0_AF0_SF6_5_AIF5_glassbeads.txt',\n",
       "  '20210803_1152_PF77_AF8_3_SF6_5_AIF5_glassbeads_Set3.txt',\n",
       "  '20210803_1222_PF77_AF8_6_SF6_5_AIF5_glassbeads_Set5.txt',\n",
       "  '20210803_1108_PF77_AF8_SF6_5_AIF5_glassbeads_Set1.txt',\n",
       "  '20210803_1047_PF0_AF0_SF_6.5_background_glassbeads.txt',\n",
       "  '20210803_1257_PF0_AF0_SF6_5_AIF5_glassbeads_Set8.txt',\n",
       "  '20210803_1158_PF0_AF0_SF6_5_AIF5_new_glassbeads_Set4.txt',\n",
       "  '20210803_1244_PF0_AF0_SF6_5_AIF5_glassbeads_Set7.txt',\n",
       "  '20210803_1102_PF0_AF0_SF6_5_AIF5_new_glassbeads_Set1.txt',\n",
       "  '20210803_1131_PF0_AF0_SF6_5_AIF5_new_glassbeads_Set2.txt',\n",
       "  '20210803_1238_PF77_AF8_7_SF6_5_AIF5_glassbeads_Set6.txt',\n",
       "  '20210803_1228_PF0_AF0_SF6_5_AIF5_glassbeads_Set6.txt',\n",
       "  '20210803_1303_PF77_AF8_9_SF6_5_AIF5_glassbeads_Set8.txt',\n",
       "  '20210803_1138_PF77_AF8_1_SF6_5_AIF5_glassbeads_Set2.txt',\n",
       "  '20210803_1250_PF77_AF8_8_SF6_5_AIF5_glassbeads_Set7.txt',\n",
       "  '20210803_1146_PF0_AF0_SF6_5_AIF5_new_glassbeads_Set3.txt'],\n",
       " ['20210804_1718_PF57_AF12_7_SF6_5_AIF5_glassbeads_Set13.txt',\n",
       "  '20210804_1241_PF31_AF7_5_SF1_AIF5_glassbeads_Set1.txt',\n",
       "  '20210804_1259_PF0_AF0_SF1_AIF5_glassbeads_Set2.txt',\n",
       "  '20210804_1610_PF0_AF0_SF6_5_AIF5_glassbeads_Set8.txt',\n",
       "  '20210804_1730_PF59_AF13_1_SF6_5_AIF5_glassbeads_Set14.txt',\n",
       "  '20210804_1356_PF0_AF0_SF6_5_AIF5_glassbeads_Set6.txt',\n",
       "  '20210804_1337_PF37_AF8_7_SF6_5_AIF5_glassbeads_Set5.txt',\n",
       "  '20210804_1623_PF0_AF0_SF6_5_AIF5_glassbeads_Set9.txt',\n",
       "  '20210804_1309_PF33_AF7_9_SF6_5_AIF5_glassbeads_Set3.txt',\n",
       "  '20210804_1635_PF49_AF11_1_SF6_5_AIF5_glassbeads_Set10.txt',\n",
       "  '20210804_1320_PF35_AF8_3_SF6_5_AIF5_glassbeads_Set4.txt',\n",
       "  '20210804_1315_PF0_AF0_SF6_5_AIF5_glassbeads_Set3.txt',\n",
       "  '20210804_1543_PF41_AF9_5_SF6_5_AIF5_glassbeads_Set7.txt',\n",
       "  '20210804_1703_PF55_AF12_3_SF6_5_AIF5_glassbeads_Set12.txt',\n",
       "  '20210804_1642_PF0_AF0_SF6_5_AIF5_glassbeads_Set10.txt',\n",
       "  '20210804_1737_PF0_AF0_SF6_5_AIF5_glassbeads_Set14.txt',\n",
       "  '20210804_1617_PF47_AF10_7_SF6_5_AIF5_glassbeads_Set9.txt',\n",
       "  '20210804_1657_PF0_AF0_SF6_5_AIF5_glassbeads_Set11.txt',\n",
       "  '20210804_1246_PF0_AF0_SF1_AIF5_glassbeads_Set1.txt',\n",
       "  '20210804_1327_PF0_AF0_SF6_5_AIF5_glassbeads_Set4.txt',\n",
       "  '20210804_1253_PF33_AF7_9_SF1_AIF5_glassbeads_Set2.txt',\n",
       "  '20210804_1710_PF0_AF0_SF6_5_AIF5_glassbeads_Set12.txt',\n",
       "  '20210804_1151_empty_bottle_test.txt',\n",
       "  '20210804_1602_PF45_AF10_3_SF6_5_AIF5_glassbeads_Set8.txt',\n",
       "  '20210804_1724_PF0_AF0_SF6_5_AIF5_glassbeads_Set13.txt',\n",
       "  '20210804_1221_PF0_AF0_SF6_5_AIF5_glassbeads.txt',\n",
       "  '20210804_1351_PF39_AF9_1_SF6_5_AIF5_glassbeads_Set6.txt',\n",
       "  '20210804_1650_PF53_AF11_9_SF6_5_AIF5_glassbeads_Set11.txt',\n",
       "  '20210804_1553_PF0_AF0_SF6_5_AIF5_glassbeads_Set7.txt',\n",
       "  '20210804_1344_PF0_AF0_SF6_5_AIF5_glassbeads_Set5.txt'],\n",
       " ['20210805_1550_PF45_AF7_21_SF6_5_AIF5_glassbeads_Set4.txt',\n",
       "  '20210805_1437_PF37_AF8_24_SF6_5_AIF5_glassbeads_Set2.txt',\n",
       "  '20210805_1556_PF0_AF0_SF6_5_AIF5_glassbeads_Set4.txt',\n",
       "  '20210805_1430_PF0_AF0_SF6_5_AIF5_glassbeads_Set1.txt',\n",
       "  '20210805_1449_PF37_AF9_27_SF6_5_AIF5_glassbeads_Set3.txt',\n",
       "  '20210805_1443_PF0_AF0_SF6_5_AIF5_glassbeads_Set2.txt',\n",
       "  '20210805_1423_PF37_AF7_21_SF6_5_AIF5_glassbeads_Set1.txt',\n",
       "  '20210805_1455_PF0_AF0_SF6_5_AIF5_glassbeads_Set3.txt'],\n",
       " ['20210802_1235_test_glassbeads.txt',\n",
       "  '20210802_1426_test_after_cleaning.txt',\n",
       "  '20210802_1222_PF0_AF0_SF6_5_AIF5_NEWglassbeads_test.txt'],\n",
       " ['20210728_1247_PF0_AF0_SF6_5_AIF5_glassbeads_Set6.txt',\n",
       "  '20210728_1127_PF0_AF0_SF6_5_AIF5_glassbeads_Set2.txt',\n",
       "  '20210728_1111_PF0_AF0_SF6_5_AIF5_glassbeads_Set1.txt',\n",
       "  '20210728_1122_PF81_AF9_SF6_5_AIF5_glassbeads_Set2.txt',\n",
       "  '20210728_1134_PF81_AF11_SF6_5_AIF5_glassbeads_Set3.txt',\n",
       "  '20210728_1225_PF83_AF9_SF6_5_AIF5_glassbeads_Set5.txt',\n",
       "  '20210728_1232_PF0_AF0_SF6_5_AIF5_glassbeads_Set5.txt',\n",
       "  '20210728_1157_PF0_AF0_SF6_5_AIF5_glassbeads_Set4.txt',\n",
       "  '20210728_1102_PF81_AF7_SF6_5_AIF5_glassbeads_Set1.txt',\n",
       "  '20210728_1117_leaktest.txt',\n",
       "  '20210728_1140_PF0_AF0_SF6_5_AIF5_glassbeads_Set3.txt',\n",
       "  '20210728_1259_PF0_AF0_SF6_5_AIF5_glassbeads_Set7.txt',\n",
       "  '20210728_1346_PF0_AF0_SF6_5_AIF5_glassbeads_Set8.txt',\n",
       "  '20210728_1353_PF87_AF7_SF6_5_AIF5_glassbeads_Set8.txt',\n",
       "  '20210728_1147_PF83_AF7_SF6_5_AIF5_glassbeads_Set4.txt',\n",
       "  '20210728_1305_PF85_AF9_SF6_5_AIF5_glassbeads_Set7.txt',\n",
       "  '20210728_1253_PF85_AF7_SF6_5_AIF5_glassbeads_Set6.txt'],\n",
       " ['20210721_1706_PF0_AF0_SF6_5_leak_test.txt'],\n",
       " ['20210719_1517_contaminant_test.txt', '20210719_1558_background.txt'],\n",
       " ['20210727_1740_PF79_AF9_SF6_5_AIF5_glassbeads_Set19.txt',\n",
       "  '20210727_1456_PF0_AF0_SF6_5_AIF5_glassbeads_Set7.txt',\n",
       "  '20210727_1513_PF76_AF13_SF6_5_AIF5_glassbeads_Set9.txt',\n",
       "  '20210727_1702_PF78_AF10_SF6_5_AIF5_glassbeads_Set16.txt',\n",
       "  '20210727_1655_PF0_AF0_SF6_5_AIF5_glassbeads_Set15.txt',\n",
       "  '20210727_1650_PF78_AF9_SF6_5_AIF5_glassbeads_Set15.txt',\n",
       "  '20210727_1618_PF0_AF0_SF6_5_AIF5_glassbeads_Set13.txt',\n",
       "  '20210727_1720_PF0_AF0_SF6_5_AIF5_glassbeads_Set17.txt',\n",
       "  '20210727_1541_PF0_AF0_SF6_5_AIF5_glassbeads_Set10.txt',\n",
       "  '20210727_1802_PF0_AF0_SF6_5_AIF5_glassbeads_Set20.txt',\n",
       "  '20210727_1406_PF0_AF0_SF6_5_AIF5_glassbeads_Set3.txt',\n",
       "  '20210727_1400_PF75_AF11_SF6_5_AIF5_glassbeads_Set3.txt',\n",
       "  '20210727_1728_PF79_AF7_SF6_5_AIF5_glassbeads_Set18.txt',\n",
       "  '20210727_1501_PF76_AF11_SF6_5_AIF5_glassbeads_Set8.txt',\n",
       "  '20210727_1746_PF0_AF0_SF6_5_AIF5_glassbeads_Set19.txt',\n",
       "  '20210727_1730_PF0_AF0_SF6_5_AIF5_glassbeads_Set18.txt',\n",
       "  '20210727_1340_PF0_AF0_SF6_5_AIF5_glassbeads_Set1.txt',\n",
       "  '20210727_1600_PF77_AF10_SF6_5_AIF5_glassbeads_Set12.txt',\n",
       "  '20210727_1606_PF0_AF0_SF6_5_AIF5_glassbeads_Set12.txt',\n",
       "  '20210727_1755_PF79_AF11_SF6_5_AIF5_glassbeads_Set20.txt',\n",
       "  '20210727_1413_PF75_AF13_SF6_5_AIF5_glassbeads_Set4.txt',\n",
       "  '20210727_1431_PF0_AF0_SF6_5_AIF5_glassbeads_Set5.txt',\n",
       "  '20210727_1352_PF0_AF0_SF6_5_AIF5_glassbeads_Set2.txt',\n",
       "  '20210727_1554_PF0_AF0_SF6_5_AIF5_glassbeads_Set11.txt',\n",
       "  '20210727_1614_PF77_AF11_SF6_5_AIF5_glassbeads_Set13.txt',\n",
       "  '20210727_1708_PF0_AF0_SF6_5_AIF5_glassbeads_Set16.txt',\n",
       "  '20210727_1715_PF78_AF11_SF6_5_AIF5_glassbeads_Set17.txt',\n",
       "  '20210727_1508_PF0_AF0_SF6_5_AIF5_glassbeads_Set8.txt',\n",
       "  '20210727_1325_PF75_AF7_SF6_5_AIF5_glassbeads_Set1.txt',\n",
       "  '20210727_1642_PF0_AF0_SF6_5_AIF5_glassbeads_Set14.txt',\n",
       "  '20210727_1425_PF75_AF15_SF6_5_AIF5_glassbeads_Set5.txt',\n",
       "  '20210727_1521_PF0_AF0_SF6_5_AIF5_glassbeads_Set9.txt',\n",
       "  '20210727_1536_PF77_AF7_SF6_5_AIF5_glassbeads_Set10.txt',\n",
       "  '20210727_1347_PF75_AF9_SF6_5_AIF5_glassbeads_Set2.txt',\n",
       "  '20210727_1549_PF77_AF9_SF6_5_AIF5_glassbeads_Set11.txt',\n",
       "  '20210727_1418_PF0_AF0_SF6_5_AIF5_glassbeads_Set4.txt',\n",
       "  '20210727_1635_PF78_AF7_SF6_5_AIF5_glassbeads_Set14.txt',\n",
       "  '20210727_1438_PF76_AF7_SF6_5_AIF5_glassbeads_Set6.txt',\n",
       "  '20210727_1450_PF76_AF9_SF6_5_AIF5_glassbeads_Set7.txt',\n",
       "  '20210727_1444_PF0_AF0_SF6_5_AIF5_glassbeads_Set6.txt'],\n",
       " ['20210720_1439_PF51_AF7_SF6_5_glassbeads_Set2.txt',\n",
       "  '20210720_1420_PF0_AF0_SF6_7_glassbeads_Set1.txt',\n",
       "  '20210720_1524_PF0_AF0_SF6_5_glassbeads_Set3.txt',\n",
       "  '20210720_1351_PF43_AF10_SF6_7_ambient_nofilter.txt',\n",
       "  '20210720_1412_PF43_AF10_SF6_7_glassbeads_Set1.txt',\n",
       "  '20210720_1428_PF0_AF10_SF6_7_glassbeads_Set1.txt',\n",
       "  '20210720_1511_PF56_AF12_SF6_5_glassbeads_Set3.txt',\n",
       "  '20210720_1449_PF0_AF7_SF6_5_glassbeads_Set2.txt',\n",
       "  '20210720_1455_PF0_AF0_SF6_5_glassbeads_Set2.txt',\n",
       "  '20210720_1518_PF0_AF12_SF6_5_glassbeads_Set3.txt'],\n",
       " ['20210809_1603_PF47_AF8_16_SF6_5_AIF5_glassbeads_Set7.txt',\n",
       "  '20210809_1050_PF45_AF7_86_SF6_5_AIF5_glassbeads_Set2.txt',\n",
       "  '20210809_1658_PF0_AF0_SF6_5_AIF5_glassbeads_Set8.txt',\n",
       "  '20210809_1650_PF47_AF8_92_SF6_5_AIF5_glassbeads_Set8.txt',\n",
       "  '20210809_1110_PF0_AF0_SF6_5_AIF5_glassbeads_Set3.txt',\n",
       "  '20210809_1532_PF47_AF6_57_SF6_5_AIF5_glassbeads_Set5.txt',\n",
       "  '20210809_1042_PF0_AF0_SF6_5_AIF5_glassbeads_Set1.txt',\n",
       "  '20210809_1117_PF45_AF8_58_SF6_5_AIF5_glassbeads_Set4.txt',\n",
       "  '20210809_1548_PF47_AF7_37_SF6_5_AIF5_glassbeads_Set6.txt',\n",
       "  '20210809_1104_PF45_AF7_1_SF6_5_AIF5_glassbeads_Set3.txt',\n",
       "  '20210809_1124_PF0_AF0_SF6_5_AIF5_glassbeads_Set4.txt',\n",
       "  '20210809_1056_PF0_AF0_SF6_5_AIF5_glassbeads_Set2.txt',\n",
       "  '20210809_1618_PF0_AF0_SF6_5_AIF5_glassbeads_Set7.txt',\n",
       "  '20210809_1027_PF45_AF6_32_SF6_5_AIF5_glassbeads_Set1.txt',\n",
       "  '20210809_1554_PF0_AF0_SF6_5_AIF5_glassbeads_Set6.txt',\n",
       "  '20210809_1541_PF0_AF0_SF6_5_AIF5_glassbeads_Set5.txt']]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "APS_directories = [d for d in os.listdir(import_APS) if not(d.startswith('.'))]\n",
    "\n",
    "APS_paths = [import_APS + k + \"/csv_files/\" for k in APS_directories]\n",
    "\n",
    "APS_files = [os.listdir(f) for f in APS_paths]\n",
    "APS_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SECTION:** Loop through directories and retrieve file information using regular expressions (regex) with module re. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define empty dictionary\n",
    "D = {}\n",
    "\n",
    "# OPEN LOOP\n",
    "for i in range(0, len(APS_files), 1):\n",
    "    \n",
    "    # Generate temporary variable\n",
    "    x = APS_files[i]\n",
    "    \n",
    "    # Removes system temporary files (such as a .DStore file)\n",
    "    x = [f for f in x if not(f.startswith('.'))]\n",
    "    \n",
    "    # Initialize dictionary\n",
    "    file_information = {\n",
    "        'File': [],\n",
    "        'Path': [],\n",
    "        'Date': [],\n",
    "        'Time': [],\n",
    "        'PF': [],\n",
    "        'AF': [],\n",
    "        'SF': [],\n",
    "        'AIF': [],\n",
    "        'Type': [],\n",
    "        'Experiment Set #': []\n",
    "    }\n",
    "    \n",
    "    # Second loop which goes through the items within the dated directory\n",
    "    for j in range(0, len(x), 1):\n",
    "        \n",
    "        # Extract the necessary information from filenames\n",
    "        File = x[j]\n",
    "        Path = APS_paths[i] + File \n",
    "        Date = x[j][0:4] + '-' + x[j][4:6] + '-' + x[j][6:8]\n",
    "        Time = x[j][9:13]\n",
    "        \n",
    "        # These are simple regex patterns where it looks for the literal strings PF, AF, etc. then looks for 1 or more digits with potentially a _ or . after\n",
    "        # It then also looks ahead to see if there are zero or more digits after the _ or . if present\n",
    "        PF = str(re.findall(r'PF\\d+[_.]?\\d*', x[j]))\n",
    "        AF = str(re.findall(r'AF\\d+[_.]?\\d*', x[j]))\n",
    "        SF = str(re.findall(r'SF\\d+[_.]?\\d*', x[j]))\n",
    "        AIF = str(re.findall(r'AIF\\d+[_]?\\d*', x[j]))\n",
    "        \n",
    "        # Experiment Set\n",
    "        # This part is crucial in matcing samples together for comparing inlet and outlets\n",
    "        ID = str(re.findall(r'Set\\d+', x[j]))\n",
    "\n",
    "        # If else ladder\n",
    "        # Missing value code is 9999 as Python is obnoxious about interpreting NA's\n",
    "        if PF != \"[]\":\n",
    "            PF = float(PF.replace('_', '.').replace('PF', '').replace(\"['\", '').replace(\"']\", ''))\n",
    "        else:\n",
    "            PF = 9999\n",
    "        if AF != \"[]\":\n",
    "            AF = float(AF.replace('_', '.').replace('AF', '').replace(\"['\", '').replace(\"']\", ''))\n",
    "        else:\n",
    "            AF = 9999\n",
    "        if SF != \"[]\":\n",
    "            SF = float(SF.replace('_', '.').replace('SF', '').replace(\"['\", '').replace(\"']\", ''))\n",
    "        else:\n",
    "            SF = 9999\n",
    "            \n",
    "        if AIF != \"[]\":\n",
    "            AIF = AIF.replace('_', '.').replace('AIF', '').replace(\"['\", '').replace(\"']\", '')\n",
    "        if AIF == '[]':\n",
    "            AIF = str(re.findall(r'\\d+[_]?lpm', x[j]))\n",
    "        if AIF != '[]':\n",
    "            AIF = float(AIF.replace('lpm', '').replace(\"['\", '').replace(\"']\", ''))\n",
    "        else:\n",
    "            AIF = 1\n",
    "        if ID != '[]':\n",
    "            ID = float(ID.replace('Set', '').replace(\"['\", '').replace(\"']\", ''))\n",
    "        else:\n",
    "            ID = 'NA'\n",
    "            \n",
    "        # Append values to dictionary\n",
    "        file_information[\"File\"].append(File)\n",
    "        file_information[\"Path\"].append(Path)\n",
    "        file_information[\"Date\"].append(Date)\n",
    "        file_information[\"Time\"].append(Time)\n",
    "        file_information[\"PF\"].append(PF)\n",
    "        file_information[\"AF\"].append(AF)\n",
    "        file_information[\"SF\"].append(SF)\n",
    "        file_information[\"AIF\"].append(AIF)\n",
    "        file_information[\"Experiment Set #\"].append(ID)\n",
    "        \n",
    "    # Dataframe conversion\n",
    "    file_info_df = pd.DataFrame.from_dict(file_information, orient = 'index')\n",
    "    D[i] = file_info_df.transpose()\n",
    "    \n",
    "    # CLOSE LOOP   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SECTION:** Creates a column of type based on combination of PF, AF, and other identifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = {}\n",
    "for i in range(0, len(D), 1):\n",
    "    \n",
    "    # Copy the dataframe to avoid overwriting\n",
    "    tmp = D[i].copy(deep = True)\n",
    "\n",
    "    # Convert time to a float variable\n",
    "    #tmp[\"Time\"] = tmp[\"Time\"].astype(\"float\")\n",
    "    #tmp = tmp.sort_values(\"Time\").reset_index().drop(columns = [\"index\"])\n",
    "    \n",
    "    for j in range(0, tmp.shape[0], 1):\n",
    "        \n",
    "        # If else ladder of checking for the flow values in the filename\n",
    "        # Substitutes values into \"Type\" depending on value\n",
    "        if (tmp[\"PF\"][j] == 0) & (tmp[\"AF\"][j] == 0):\n",
    "            tmp.loc[j, [\"Type\"]] = \"Inlet\"\n",
    "        elif (tmp[\"PF\"][j] == 0) & (tmp[\"AF\"][j] != 0):\n",
    "            tmp.loc[j, [\"Type\"]] = \"AF Only\"\n",
    "        elif (tmp[\"PF\"][j] == 9999) & (tmp[\"AF\"][j] == 9999) & (tmp[\"SF\"][j] == 9999):\n",
    "            tmp.loc[j, [\"Type\"]] = \"Other\"\n",
    "        elif (tmp[\"PF\"][j] > 0) & (tmp[\"AF\"][j] > 0):\n",
    "            tmp.loc[j, [\"Type\"]] = \"Outlet\" \n",
    "    \n",
    "    # Replace 9999 with numpy NaN\n",
    "    tmp = tmp.replace(9999, np.nan)\n",
    "            \n",
    "    F[i] = tmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbreviations:\n",
    "\n",
    "* Inlet Flow (IF)\n",
    "* Add Flow (AF)\n",
    "* Pump Flow (PF)\n",
    "* Sample Flow (SF)\n",
    "* Effective Counter Flow (ECF)\n",
    "* Counter Flow (CF)\n",
    "\n",
    "PCVI Flow Equilibrium:\n",
    "\n",
    "$$ IN = OUT $$\n",
    "\n",
    "$$ IF + AF = PF + SF \\,\\,\\,\\,\\, \\Longleftrightarrow \\,\\,\\,\\,\\, IF = PF + SF - AF $$\n",
    "\n",
    "Other Definitions:\n",
    "\n",
    "$$ ECF = $$\n",
    "\n",
    "$$ CF = $$ \n",
    "\n",
    "Transmission Efficiency: $$ \\frac{Outlet\\ Concentration\\ cm^{-3}}{Inlet\\ Concentration\\ cm^{-3}} \\cdot \\frac{Sample\\ Flow\\ (L\\cdot\\min^{-1})}{Inlet\\ Flow\\ (L\\cdot\\min^{-1})} $$\n",
    "\n",
    "\n",
    "Logistic Curve (Sigmoid Curve):\n",
    "\n",
    "$$ D(t)\\ = \\frac{L}{1+e^{-k(x-x_{0})}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SECTION:** Simple for loop to add categorical labels to the list of files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(F), 1):\n",
    "    \n",
    "    # Temporary variable of dataframe of files for dated directory\n",
    "    X = F[i]\n",
    "\n",
    "    for j in range(0, X.shape[0], 1):\n",
    "        \n",
    "        # Temporary variable for individual files in X\n",
    "        y = X[\"File\"][j]\n",
    "\n",
    "        # If else chain using re.search to detect strings in filenames\n",
    "        if re.search(\"test\", y) != None:\n",
    "            X.loc[j, ['Type']] = \"Test\"\n",
    "        elif re.search(\"ambient\", y) != None:\n",
    "            X.loc[j, ['Type']] = \"Ambient\"\n",
    "        elif re.search(\"inlet\", y) != None:\n",
    "            X.loc[j, ['Type']] = \"Inlet\"\n",
    "            X.loc[j, ['PF']] = 0\n",
    "            X.loc[j, ['AF']] = 0\n",
    "    \n",
    "    # Calculate IF\n",
    "    X[\"IF\"] = X[\"PF\"] + X[\"SF\"] - X[\"AF\"]\n",
    "    \n",
    "    # Reassignment\n",
    "    F[i] = X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Path</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "      <th>PF</th>\n",
       "      <th>AF</th>\n",
       "      <th>SF</th>\n",
       "      <th>AIF</th>\n",
       "      <th>Type</th>\n",
       "      <th>Experiment Set #</th>\n",
       "      <th>IF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20210714_1102_test.txt</td>\n",
       "      <td>/Users/christopherrapp/Documents/Purdue/Data_S...</td>\n",
       "      <td>2021-07-14</td>\n",
       "      <td>1102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20210714_1503_PF0_AF0_SF6_5_Set1.txt</td>\n",
       "      <td>/Users/christopherrapp/Documents/Purdue/Data_S...</td>\n",
       "      <td>2021-07-14</td>\n",
       "      <td>1503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Inlet</td>\n",
       "      <td>1</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20210714_1440_test.txt</td>\n",
       "      <td>/Users/christopherrapp/Documents/Purdue/Data_S...</td>\n",
       "      <td>2021-07-14</td>\n",
       "      <td>1440</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Test</td>\n",
       "      <td>NA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20210714_1451_PF35_AF5_SF6_5_Set1.txt</td>\n",
       "      <td>/Users/christopherrapp/Documents/Purdue/Data_S...</td>\n",
       "      <td>2021-07-14</td>\n",
       "      <td>1451</td>\n",
       "      <td>35.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Outlet</td>\n",
       "      <td>1</td>\n",
       "      <td>36.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20210714_1515_PF40_AF5_6_SF6_5_Set2.txt</td>\n",
       "      <td>/Users/christopherrapp/Documents/Purdue/Data_S...</td>\n",
       "      <td>2021-07-14</td>\n",
       "      <td>1515</td>\n",
       "      <td>40.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Outlet</td>\n",
       "      <td>2</td>\n",
       "      <td>40.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20210909_1320_PF45_AF6.7_SF6.5_AIF5_glassbeads...</td>\n",
       "      <td>/Users/christopherrapp/Documents/Purdue/Data_S...</td>\n",
       "      <td>2021-09-09</td>\n",
       "      <td>1320</td>\n",
       "      <td>45.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Outlet</td>\n",
       "      <td>5</td>\n",
       "      <td>44.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20210909_1304_PF0_AF0_SF6.5_AIF5_glassbeads_Se...</td>\n",
       "      <td>/Users/christopherrapp/Documents/Purdue/Data_S...</td>\n",
       "      <td>2021-09-09</td>\n",
       "      <td>1304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Inlet</td>\n",
       "      <td>2</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20210909_1312_PF45_AF6.8_SF6.5_AIF5_glassbeads...</td>\n",
       "      <td>/Users/christopherrapp/Documents/Purdue/Data_S...</td>\n",
       "      <td>2021-09-09</td>\n",
       "      <td>1312</td>\n",
       "      <td>45.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Outlet</td>\n",
       "      <td>4</td>\n",
       "      <td>44.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20210909_1317_PF0_AF0_SF6.5_AIF5_glassbeads_Se...</td>\n",
       "      <td>/Users/christopherrapp/Documents/Purdue/Data_S...</td>\n",
       "      <td>2021-09-09</td>\n",
       "      <td>1317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Inlet</td>\n",
       "      <td>4</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20210909_1327_PF0_AF0_SF6.5_AIF5_glassbeads_Se...</td>\n",
       "      <td>/Users/christopherrapp/Documents/Purdue/Data_S...</td>\n",
       "      <td>2021-09-09</td>\n",
       "      <td>1327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Inlet</td>\n",
       "      <td>6</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>248 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 File  \\\n",
       "0                              20210714_1102_test.txt   \n",
       "2                20210714_1503_PF0_AF0_SF6_5_Set1.txt   \n",
       "3                              20210714_1440_test.txt   \n",
       "4               20210714_1451_PF35_AF5_SF6_5_Set1.txt   \n",
       "5             20210714_1515_PF40_AF5_6_SF6_5_Set2.txt   \n",
       "..                                                ...   \n",
       "5   20210909_1320_PF45_AF6.7_SF6.5_AIF5_glassbeads...   \n",
       "0   20210909_1304_PF0_AF0_SF6.5_AIF5_glassbeads_Se...   \n",
       "1   20210909_1312_PF45_AF6.8_SF6.5_AIF5_glassbeads...   \n",
       "3   20210909_1317_PF0_AF0_SF6.5_AIF5_glassbeads_Se...   \n",
       "2   20210909_1327_PF0_AF0_SF6.5_AIF5_glassbeads_Se...   \n",
       "\n",
       "                                                 Path        Date  Time    PF  \\\n",
       "0   /Users/christopherrapp/Documents/Purdue/Data_S...  2021-07-14  1102   NaN   \n",
       "2   /Users/christopherrapp/Documents/Purdue/Data_S...  2021-07-14  1503   0.0   \n",
       "3   /Users/christopherrapp/Documents/Purdue/Data_S...  2021-07-14  1440   NaN   \n",
       "4   /Users/christopherrapp/Documents/Purdue/Data_S...  2021-07-14  1451  35.0   \n",
       "5   /Users/christopherrapp/Documents/Purdue/Data_S...  2021-07-14  1515  40.0   \n",
       "..                                                ...         ...   ...   ...   \n",
       "5   /Users/christopherrapp/Documents/Purdue/Data_S...  2021-09-09  1320  45.0   \n",
       "0   /Users/christopherrapp/Documents/Purdue/Data_S...  2021-09-09  1304   0.0   \n",
       "1   /Users/christopherrapp/Documents/Purdue/Data_S...  2021-09-09  1312  45.0   \n",
       "3   /Users/christopherrapp/Documents/Purdue/Data_S...  2021-09-09  1317   0.0   \n",
       "2   /Users/christopherrapp/Documents/Purdue/Data_S...  2021-09-09  1327   0.0   \n",
       "\n",
       "     AF   SF  AIF    Type Experiment Set #    IF  \n",
       "0   NaN  NaN  1.0    Test               NA   NaN  \n",
       "2   0.0  6.5  1.0   Inlet                1   6.5  \n",
       "3   NaN  NaN  1.0    Test               NA   NaN  \n",
       "4   5.0  6.5  1.0  Outlet                1  36.5  \n",
       "5   5.6  6.5  1.0  Outlet                2  40.9  \n",
       "..  ...  ...  ...     ...              ...   ...  \n",
       "5   6.7  6.5  5.0  Outlet                5  44.8  \n",
       "0   0.0  6.5  5.0   Inlet                2   6.5  \n",
       "1   6.8  6.5  5.0  Outlet                4  44.7  \n",
       "3   0.0  6.5  5.0   Inlet                4   6.5  \n",
       "2   0.0  6.5  5.0   Inlet                6   6.5  \n",
       "\n",
       "[248 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print all the files available\n",
    "all_files_df = pd.DataFrame()\n",
    "for i in range(0, len(F), 1):    \n",
    "    all_files_df = all_files_df.append(F[i])\n",
    "\n",
    "all_files_df = all_files_df.sort_values(\"Date\")\n",
    "all_files_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-08-10 1250 Experiment #: 1\n",
      "2021-08-10 1335 Experiment #: 2\n",
      "2021-08-10 1348 Experiment #: 3\n",
      "2021-08-10 1423 Experiment #: 4\n",
      "2021-08-10 1449 Experiment #: 5\n",
      "2021-08-10 1456 Experiment #: 6\n",
      "2021-08-10 1522 Experiment #: 7\n",
      "2021-08-10 1535 Experiment #: 8\n",
      "2021-08-10 1550 Experiment #: 9\n",
      "2021-08-10 1558 Experiment #: 10\n",
      "2021-08-10 1611 Experiment #: 11\n",
      "2021-09-09 1258 Experiment #: 1\n",
      "2021-09-09 1304 Experiment #: 2\n",
      "2021-09-09 1310 Experiment #: 3\n",
      "2021-09-09 1312 Experiment #: 4\n",
      "2021-09-09 1322 Experiment #: 5\n",
      "2021-09-09 1327 Experiment #: 6\n",
      "2021-09-01 1629 Experiment #: 1\n",
      "2021-09-01 1646 Experiment #: 2\n",
      "2021-09-01 1650 Experiment #: 3\n",
      "2021-09-01 1700 Experiment #: 4\n",
      "2021-09-01 1709 Experiment #: 5\n",
      "2021-09-01 1719 Experiment #: 6\n",
      "2021-07-31 1722 Experiment #: 1\n",
      "2021-07-31 1738 Experiment #: 2\n",
      "2021-07-31 1750 Experiment #: 3\n",
      "2021-07-31 1804 Experiment #: 4\n",
      "2021-07-31 1821 Experiment #: 5\n",
      "2021-07-31 1834 Experiment #: 6\n",
      "2021-07-31 1851 Experiment #: 7\n",
      "2021-07-31 1857 Experiment #: 8\n",
      "2021-07-14 1503 Experiment #: 1\n",
      "2021-07-14 1503 Experiment #: 2\n",
      "Error - curve_fit failed\n",
      "2021-07-22 1113 Experiment #: 1\n",
      "2021-07-22 1156 Experiment #: 2\n",
      "2021-07-22 1222 Experiment #: 3\n",
      "2021-07-22 1251 Experiment #: 4\n",
      "2021-07-22 1323 Experiment #: 5\n",
      "2021-07-22 1441 Experiment #: 6\n",
      "Error - curve_fit failed\n",
      "2021-07-22 1457 Experiment #: 7\n",
      "2021-07-22 1510 Experiment #: 8\n",
      "Error - curve_fit failed\n",
      "2021-07-15 1245 Experiment #: 1\n",
      "2021-07-15 1219 Experiment #: 2\n",
      "2021-08-03 1108 Experiment #: 1\n",
      "2021-08-03 1131 Experiment #: 2\n",
      "2021-08-03 1152 Experiment #: 3\n",
      "2021-08-03 1207 Experiment #: 4\n",
      "2021-08-03 1213 Experiment #: 5\n",
      "2021-08-03 1238 Experiment #: 6\n",
      "2021-08-03 1244 Experiment #: 7\n",
      "2021-08-03 1257 Experiment #: 8\n",
      "2021-08-04 1241 Experiment #: 1\n",
      "2021-08-04 1259 Experiment #: 2\n",
      "2021-08-04 1309 Experiment #: 3\n",
      "2021-08-04 1320 Experiment #: 4\n",
      "2021-08-04 1337 Experiment #: 5\n",
      "2021-08-04 1356 Experiment #: 6\n",
      "2021-08-04 1543 Experiment #: 7\n",
      "2021-08-04 1610 Experiment #: 8\n",
      "2021-08-04 1623 Experiment #: 9\n",
      "2021-08-04 1635 Experiment #: 10\n",
      "2021-08-04 1657 Experiment #: 11\n",
      "2021-08-04 1703 Experiment #: 12\n",
      "2021-08-04 1718 Experiment #: 13\n",
      "2021-08-04 1730 Experiment #: 14\n",
      "2021-08-05 1430 Experiment #: 1\n",
      "Error - curve_fit failed\n",
      "2021-08-05 1437 Experiment #: 2\n",
      "2021-08-05 1449 Experiment #: 3\n",
      "2021-08-05 1550 Experiment #: 4\n",
      "2021-07-28 1111 Experiment #: 1\n",
      "2021-07-28 1127 Experiment #: 2\n",
      "2021-07-28 1134 Experiment #: 3\n",
      "2021-07-28 1157 Experiment #: 4\n",
      "2021-07-28 1225 Experiment #: 5\n",
      "2021-07-28 1247 Experiment #: 6\n",
      "2021-07-28 1259 Experiment #: 7\n",
      "2021-07-28 1346 Experiment #: 8\n",
      "2021-07-27 1340 Experiment #: 1\n",
      "2021-07-27 1352 Experiment #: 2\n",
      "2021-07-27 1406 Experiment #: 3\n",
      "2021-07-27 1413 Experiment #: 4\n",
      "2021-07-27 1431 Experiment #: 5\n",
      "2021-07-27 1438 Experiment #: 6\n",
      "2021-07-27 1456 Experiment #: 7\n",
      "2021-07-27 1501 Experiment #: 8\n",
      "2021-07-27 1513 Experiment #: 9\n",
      "2021-07-27 1541 Experiment #: 10\n",
      "2021-07-27 1554 Experiment #: 11\n",
      "2021-07-27 1600 Experiment #: 12\n",
      "2021-07-27 1618 Experiment #: 13\n",
      "2021-07-27 1642 Experiment #: 14\n",
      "2021-07-27 1655 Experiment #: 15\n",
      "2021-07-27 1702 Experiment #: 16\n",
      "2021-07-27 1720 Experiment #: 17\n",
      "2021-07-27 1728 Experiment #: 18\n",
      "2021-07-27 1740 Experiment #: 19\n",
      "2021-07-27 1802 Experiment #: 20\n",
      "2021-07-20 1420 Experiment #: 1\n",
      "2021-07-20 1439 Experiment #: 2\n",
      "2021-07-20 1524 Experiment #: 3\n",
      "2021-08-09 1042 Experiment #: 1\n",
      "2021-08-09 1050 Experiment #: 2\n",
      "2021-08-09 1110 Experiment #: 3\n",
      "2021-08-09 1117 Experiment #: 4\n",
      "2021-08-09 1532 Experiment #: 5\n",
      "2021-08-09 1548 Experiment #: 6\n",
      "2021-08-09 1603 Experiment #: 7\n",
      "2021-08-09 1658 Experiment #: 8\n"
     ]
    }
   ],
   "source": [
    "# Initialize dictionary\n",
    "results = {\n",
    "    'Date': [],\n",
    "    'ID': [],\n",
    "    'PF': [],\n",
    "    'AF': [],\n",
    "    'SF': [],\n",
    "    'AIF': [],\n",
    "    'IF': [],\n",
    "    'AF:IF Ratio': [],\n",
    "    'Maximum Transimission Efficiency': [],\n",
    "    'D50': [],\n",
    "    'D50 SD': []\n",
    "}\n",
    "\n",
    "# Loop through dated directories for all matched inlet and outlet files\n",
    "for i in range(0, len(F), 1):\n",
    "    \n",
    "    # Create a temporary variable of the file information dataframe\n",
    "    X = F[i]\n",
    "    \n",
    "    # If the experiment ID is not present, then it will omit the row for future analysis\n",
    "    X = X.loc[X['Experiment Set #'] != 'NA'].reset_index().drop(columns = [\"index\"])\n",
    "    \n",
    "    # Only consider non-empty dataframes due to line above potentially deleting all variables\n",
    "    if len(X) > 0:\n",
    "        \n",
    "        # Determine the unique number of experiment sets\n",
    "        sets = X['Experiment Set #'].nunique()\n",
    "        \n",
    "        # Loop that goes through each set\n",
    "        for j in range(0, sets, 1):\n",
    "            \n",
    "            # Add one to the index because Python indexes at 0 and Experiment ID's start at 1\n",
    "            ID = j+1\n",
    "            \n",
    "            # Subset based on experiment ID\n",
    "            Y = X.loc[X['Experiment Set #'] == ID].reset_index().drop(columns = [\"index\"])\n",
    "\n",
    "            # First date value for an experiment set will always be the same as the second sample\n",
    "            date = Y[\"Date\"][0]\n",
    "\n",
    "            # Format the date string\n",
    "            date = datetime.strptime(date, \"%Y-%m-%d\")\n",
    "            date = datetime.strftime(date, format = \"%Y-%m-%d\")\n",
    "            \n",
    "            # Print the date and experiment set ID during the loop\n",
    "            print(date, Y[\"Time\"][0], 'Experiment #:', ID)\n",
    "            \n",
    "            # Y is the samples pertaining to an experiment set\n",
    "            for k in range(0, len(Y), 1):\n",
    "                \n",
    "                PF = max(Y['PF'])\n",
    "                AF = max(Y['AF'])\n",
    "                SF = max(Y['SF'])\n",
    "                AIF = max(Y['AIF'])\n",
    "                IF = round(max(Y['IF']), 1)\n",
    "                \n",
    "                # Data\n",
    "                if (Y[\"Type\"][k] == \"Inlet\") == True:\n",
    "                    \n",
    "                    # Use pd.read_csv() to read in the OPS data\n",
    "                    Z = pd.read_csv(Y[\"Path\"][k], sep = ',', skip_blank_lines = True, skiprows = 6, encoding = 'latin1')\n",
    "                    Z = Z.transpose().reset_index()\n",
    "                    Z.columns = Z.iloc[0]\n",
    "                    Z = Z.drop([0])\n",
    "\n",
    "                    # Temporary string of column names\n",
    "                    tmp_nm = list(Z.columns)\n",
    "\n",
    "                    # Simple loop to obtain the indices of specific column names\n",
    "                    # Add one to each because Python index starts at 0\n",
    "                    for l in range(0, len(tmp_nm), 1):\n",
    "\n",
    "                        # this is where you specify which columns of APS data you want to keep\n",
    "                        if tmp_nm[l] == '0.965':\n",
    "                            start_index = l + 1\n",
    "                        if tmp_nm[l] == '19.81':\n",
    "                            end_index = l + 1\n",
    "                    \n",
    "                    # Pandas chaining to transpose, change types, and calculate row means\n",
    "                    # If not clear review the Pandas documentation\n",
    "                    APS_IN = Z.iloc[:, start_index:end_index].transpose().copy(deep = True).astype(\"float64\")\n",
    "                    APS_IN[\"Inlet Mean Concentration\"] = APS_IN.astype(\"float64\").mean(axis = 1)\n",
    "                    APS_IN = APS_IN.reset_index().rename(columns = {0: \"Diameter Midpoint\"})\n",
    "                    \n",
    "                # Data\n",
    "                if (Y[\"Type\"][k] == \"Outlet\") == True:\n",
    "                \n",
    "                    # Use pd.read_csv() to read in the OPS data\n",
    "                    Z = pd.read_csv(Y[\"Path\"][k], sep = ',', skip_blank_lines = True, skiprows = 6, encoding = 'latin1')\n",
    "                    Z = Z.transpose().reset_index()\n",
    "                    Z.columns = Z.iloc[0]\n",
    "                    Z = Z.drop([0])\n",
    "\n",
    "                    tmp_nm = list(Z.columns)\n",
    "\n",
    "                    # Simple loop to obtain the indices of specific column names\n",
    "                    # Add one to each because Python index starts at 0\n",
    "                    for l in range(0, len(tmp_nm), 1):\n",
    "\n",
    "                        # this is where you specify which columns of APS data you want to keep\n",
    "                        if tmp_nm[l] == '0.965':\n",
    "                            start_index = l + 1\n",
    "                        if tmp_nm[l] == '19.81':\n",
    "                            end_index = l + 1\n",
    "\n",
    "                    # Pandas chaining to transpose, change types, and calculate row means\n",
    "                    # If not clear review the Pandas documentation\n",
    "                    APS_OUT = Z.iloc[:, start_index:end_index].transpose().copy(deep = True).astype(\"float64\")\n",
    "                    APS_OUT[\"Outlet Mean Concentration\"] = APS_OUT.astype(\"float64\").mean(axis = 1)\n",
    "                    APS_OUT = APS_OUT.reset_index().rename(columns = {0: \"Diameter Midpoint\"})\n",
    "            \n",
    "            # Assigment of the values from APS_OUT, APS_IN, and flows to a combined dataframe\n",
    "            data_df = APS_IN[[\"Diameter Midpoint\", \"Inlet Mean Concentration\"]].copy(deep = True)\n",
    "            data_df['Outlet Mean Concentration'] = APS_OUT[\"Outlet Mean Concentration\"]\n",
    "            data_df['PF'] = PF\n",
    "            data_df['AF'] = AF\n",
    "            data_df['SF'] = SF\n",
    "            data_df['AIF'] = AIF\n",
    "            data_df['IF'] = round(IF, 1)\n",
    "            data_df['BF'] = IF - AIF\n",
    "            data_df['AF:IF Ratio'] = round(AF/IF, 2)\n",
    "\n",
    "            # Calculate transmission ratio\n",
    "            data_df['Outlet/Inlet'] = data_df['Outlet Mean Concentration']/data_df['Inlet Mean Concentration']\n",
    "            \n",
    "            # Calculate enhancemnet factor\n",
    "            data_df['IF/SF'] = data_df['IF']/data_df['SF']\n",
    "            \n",
    "            # Calculate transmission efficiency\n",
    "            data_df['Transmission Efficiency'] = data_df['Outlet/Inlet']/data_df['IF/SF']\n",
    "\n",
    "            # Conversion\n",
    "            data_df[\"Diameter Midpoint\"] = data_df[\"Diameter Midpoint\"].astype(\"float64\")\n",
    "\n",
    "            # FILE NAMING\n",
    "            file_label = date+\"_PF\"+str(data_df['PF'][0]).replace('.', '_')+\"_AF\"+str(data_df['AF'][0]).replace('.', '_')+\"_results\"+\".csv\"\n",
    "            file_nm = export_results + file_label\n",
    "\n",
    "            # Export File\n",
    "            data_df.to_csv(file_nm)               \n",
    "\n",
    "            # Size Distribution Plot\n",
    "            # ----------------------------------------------------------------------- #\n",
    "            \n",
    "            # Set plotting style\n",
    "            plt.style.use('ggplot')\n",
    "\n",
    "            # Define figure axes and subplots\n",
    "            fig, (ax1, ax2) = plt.subplots(2, 1, figsize = (16, 16))\n",
    "\n",
    "            # Create a title string\n",
    "            plot_title = \"L-PCVI Calibration Results -  \" + date + \" , PF = \" + str(data_df[\"PF\"][0]) + \", AF = \" + str(data_df[\"AF\"][0]) + \", SF = \" + str(data_df[\"SF\"][0]) + \", IF = \" + str(int(data_df[\"IF\"][0])) + \", AIF = \" + str(data_df[\"AIF\"][0]) + \", AF:IF Ratio = \" + str(data_df[\"AF:IF Ratio\"][0])\n",
    "\n",
    "            # Change font and type of super title\n",
    "            #fig.suptitle(plot_title)\n",
    "\n",
    "            # Indices for plot using list comprehension\n",
    "            idx = np.asarray([i for i in range(len(data_df['Diameter Midpoint']))])\n",
    "\n",
    "            # Define width\n",
    "            width = 0.8\n",
    "\n",
    "            # Create bars\n",
    "            bar1 = ax1.bar(x = idx, height = data_df['Inlet Mean Concentration'], width = width, align = \"center\", alpha = 0.5)\n",
    "            bar2 = ax1.bar(x = idx, height = data_df['Outlet Mean Concentration'], width = width, align = \"center\", alpha = 0.5)\n",
    "\n",
    "            # Plot cosmetics\n",
    "            ax1.set_title(plot_title)\n",
    "            ax1.set_xticks(idx)\n",
    "            ax1.set_xticklabels(data_df['Diameter Midpoint'], rotation = 90)\n",
    "            ax1.set_xbound(lower = -1, upper = len(data_df['Diameter Midpoint']))\n",
    "            ax1.text(-0.075, 0.5, r'Mean Concentration $\\mathrm{(cm^{-3})}$', rotation = 90, size = 12, weight = 'normal', verticalalignment='center', horizontalalignment='right', transform = ax1.transAxes)\n",
    "\n",
    "            ax1.legend([bar1, bar2], ['Inlet', 'Outlet'])\n",
    "\n",
    "            # Transmission Plot\n",
    "            # ----------------------------------------------------------------------- #\n",
    "\n",
    "            # Remove NaN's to prevent errors in curve fitting\n",
    "            data_df = data_df.dropna(thresh = 10)\n",
    "\n",
    "            # Specify variables used in plotting\n",
    "            xdata = data_df[\"Diameter Midpoint\"]\n",
    "            xdata_max = round(max(xdata), 1)\n",
    "            xdata_min = round(min(xdata), 1)\n",
    "            ydata = data_df[\"Transmission Efficiency\"]\n",
    "\n",
    "            # Create a numpy array of diameter midpoints\n",
    "            idx = np.asarray([i for i in range(len(data_df['Diameter Midpoint']))])\n",
    "            \n",
    "            # Plot transmission data\n",
    "            ax2.scatter(xdata,ydata)\n",
    "            ax2.set_xlabel(r'Aerodynamic Diameter $\\mathrm{(\\mu m)}$', size = 12, labelpad = 20)\n",
    "            ax2.text(-0.075, 0.5, \"Transmission Efficiency\", rotation = 90, size = 12, weight = 'normal', verticalalignment='center', horizontalalignment='right', transform = ax2.transAxes)\n",
    "            ax2.set_xticks(idx)\n",
    "            ax2.set_xbound(lower = 0.5, upper = 20.5)\n",
    "            ax2.set_xlim(right = (xdata_max + 1))\n",
    "\n",
    "            # CURVE FITTING\n",
    "            # ----------------------------------------------------------------------- #\n",
    "\n",
    "            # Define the sigmoid function\n",
    "            def sigmoid(x, L ,x0, k, b):\n",
    "                y = L / (1 + np.exp(-k*(x-x0)))+b\n",
    "                return (y)\n",
    "\n",
    "            # Define L\n",
    "            L = max(data_df['Transmission Efficiency']) # The maximum transmission efficiency\n",
    "\n",
    "            # Initial guess for curve_fit model\n",
    "            # REQUIRED guess to prevent RuntimeErrors from occuring constantly\n",
    "            p0 = [max(ydata), np.median(xdata), 1, min(ydata)]\n",
    "\n",
    "            try :\n",
    "                # Fit a sigmoid to the data to idenitfy the cut point\n",
    "                # Dogbox method is the most accurate however most computationally expensive\n",
    "                # Absolute sigma is not necessary here\n",
    "                popt, pcov = curve_fit(sigmoid, xdata, ydata, p0, method = 'dogbox', absolute_sigma = False, maxfev = 1000)\n",
    "                \n",
    "                failed = 0\n",
    "\n",
    "            except RuntimeError:\n",
    "                print(\"Error - curve_fit failed\")\n",
    "                \n",
    "                failed = 1\n",
    "\n",
    "            # Generate 1000 evenly spaced values between 0 and the maximum midpoint\n",
    "            # y values are the corresponding model results\n",
    "            x = np.linspace(xdata_min, xdata_max, 1000)\n",
    "            y = sigmoid(x, *popt)\n",
    "\n",
    "            # Calculate sigma values\n",
    "            sigma = np.sqrt(np.diagonal(pcov))\n",
    "\n",
    "            # Extract the cut-point\n",
    "            D50 = popt[1]\n",
    "            D50_rounded = round(D50, 2)\n",
    "            \n",
    "            # Extract the standard deviation corresponding to the cut point\n",
    "            D50_sigma = sigma[1]\n",
    "            D50_sigma = round(D50_sigma, 2)\n",
    "            \n",
    "            if failed == 0:\n",
    "                \n",
    "                # Plot best fit curve\n",
    "                ax2.plot(x, y, color = 'black', linestyle = '--')\n",
    "\n",
    "                ax2.plot(D50, sigmoid(D50, *popt), 'x', color = 'blue')\n",
    "                ax2.errorbar(x = D50, y = sigmoid(D50, *popt), xerr = D50_sigma, color = 'black')\n",
    "\n",
    "                D50_label = r'Calculated $\\mathrm{D_{50} = }$ ' + str(D50_rounded) + r' $\\mathrm{\\pm}$ ' + str(D50_sigma)\n",
    "\n",
    "                ax2.legend([\"Best Fit Curve\", D50_label, \"Transmission Efficiencies\"])\n",
    "                \n",
    "                # Generate a figure label for the filename\n",
    "                figure_label = date + \" PF\" + str(data_df['PF'][0]) + \" AF\" + str(data_df['AF'][0]) + \" Ratio\" + str(data_df[\"AF:IF Ratio\"][0]) + \" Results\" + \".png\"\n",
    "                figure_nm = export_plots + figure_label\n",
    "                \n",
    "                # Save the figure\n",
    "                plt.savefig(figure_nm, format = 'png', dpi = 400)\n",
    "\n",
    "                plt.close()\n",
    "                \n",
    "            if failed == 1:\n",
    "\n",
    "                # Generate a figure label for the filename\n",
    "                figure_label = date + \" PF\" + str(data_df['PF'][0]) + \" AF\" + str(data_df['AF'][0]) + \" Ratio\" + str(data_df[\"AF:IF Ratio\"][0]) + \" Results Failed\" + \".png\"\n",
    "                figure_nm = export_plots + figure_label\n",
    "                \n",
    "                # Save the figure\n",
    "                plt.savefig(figure_nm, format = 'png', dpi = 400)\n",
    "\n",
    "                plt.close()\n",
    "            \n",
    "            results['Date'].append(date)\n",
    "            results['ID'].append(ID)\n",
    "            results['PF'].append(PF)\n",
    "            results['AF'].append(AF)\n",
    "            results['SF'].append(SF)\n",
    "            results['AIF'].append(AIF)\n",
    "            results['IF'].append(IF)\n",
    "            results['AF:IF Ratio'].append(round(AF/IF, 2))\n",
    "            results['Maximum Transimission Efficiency'].append(round(L, 2))\n",
    "\n",
    "            if failed == 0:\n",
    "                if D50 > 0:\n",
    "                    results['D50'].append(D50_rounded)\n",
    "                    results['D50 SD'].append(D50_sigma)\n",
    "                else:\n",
    "                    results['D50'].append(\"Failed\")\n",
    "                    results['D50 SD'].append(\"Failed\")\n",
    "            else:\n",
    "                results['D50'].append(\"Failed\")\n",
    "                results['D50 SD'].append(\"Failed\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe conversion\n",
    "results_df = pd.DataFrame.from_dict(results, orient = 'index').transpose().sort_values(\"PF\", ascending = False).reset_index().drop(columns = [\"index\"])\n",
    "\n",
    "# Find the current time for exporting data\n",
    "sys_time = str(datetime.now())[0:10]\n",
    "sys_time\n",
    "\n",
    "# Filename\n",
    "file_nm = export_results + \"LPCVI_results_summary_\" + sys_time + \".csv\"\n",
    "\n",
    "# Export as a csv\n",
    "results_df.to_csv(file_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ID</th>\n",
       "      <th>PF</th>\n",
       "      <th>AF</th>\n",
       "      <th>SF</th>\n",
       "      <th>AIF</th>\n",
       "      <th>IF</th>\n",
       "      <th>AF:IF Ratio</th>\n",
       "      <th>Maximum Transimission Efficiency</th>\n",
       "      <th>D50</th>\n",
       "      <th>D50 SD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-07-28</td>\n",
       "      <td>8</td>\n",
       "      <td>87</td>\n",
       "      <td>7</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5</td>\n",
       "      <td>86.5</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-07-28</td>\n",
       "      <td>6</td>\n",
       "      <td>85</td>\n",
       "      <td>7</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5</td>\n",
       "      <td>84.5</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.05</td>\n",
       "      <td>8.55</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-07-28</td>\n",
       "      <td>7</td>\n",
       "      <td>85</td>\n",
       "      <td>9</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5</td>\n",
       "      <td>82.5</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.07</td>\n",
       "      <td>9.91</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-07-28</td>\n",
       "      <td>4</td>\n",
       "      <td>83</td>\n",
       "      <td>7</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5</td>\n",
       "      <td>82.5</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.32</td>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-07-28</td>\n",
       "      <td>5</td>\n",
       "      <td>83</td>\n",
       "      <td>9</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5</td>\n",
       "      <td>80.5</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.15</td>\n",
       "      <td>9.7</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2021-08-04</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>26.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.13</td>\n",
       "      <td>13.53</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2021-08-04</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>7.9</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5</td>\n",
       "      <td>31.6</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.82</td>\n",
       "      <td>6.86</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2021-08-04</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>24.5</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.12</td>\n",
       "      <td>12.59</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2021-07-22</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>4.48</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5</td>\n",
       "      <td>32</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.78</td>\n",
       "      <td>5.49</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2021-07-15</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>4.48</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.04</td>\n",
       "      <td>12.24</td>\n",
       "      <td>1.07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date ID  PF    AF   SF AIF    IF AF:IF Ratio  \\\n",
       "0    2021-07-28  8  87     7  6.5   5  86.5        0.08   \n",
       "1    2021-07-28  6  85     7  6.5   5  84.5        0.08   \n",
       "2    2021-07-28  7  85     9  6.5   5  82.5        0.11   \n",
       "3    2021-07-28  4  83     7  6.5   5  82.5        0.08   \n",
       "4    2021-07-28  5  83     9  6.5   5  80.5        0.11   \n",
       "..          ... ..  ..   ...  ...  ..   ...         ...   \n",
       "103  2021-08-04  2  33   7.9    1   5  26.1         0.3   \n",
       "104  2021-08-04  3  33   7.9  6.5   5  31.6        0.25   \n",
       "105  2021-08-04  1  31   7.5    1   5  24.5        0.31   \n",
       "106  2021-07-22  1  30  4.48  6.5   5    32        0.14   \n",
       "107  2021-07-15  1  30  4.48  6.5   1    32        0.14   \n",
       "\n",
       "    Maximum Transimission Efficiency    D50 D50 SD  \n",
       "0                               0.05    7.5   0.18  \n",
       "1                               0.05   8.55   0.39  \n",
       "2                               0.07   9.91   0.59  \n",
       "3                                0.5   8.32   0.24  \n",
       "4                               0.15    9.7   0.27  \n",
       "..                               ...    ...    ...  \n",
       "103                             0.13  13.53   0.41  \n",
       "104                             0.82   6.86   0.44  \n",
       "105                             0.12  12.59    0.5  \n",
       "106                             0.78   5.49    0.1  \n",
       "107                             0.04  12.24   1.07  \n",
       "\n",
       "[108 rows x 11 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
